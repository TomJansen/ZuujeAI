{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZuujeAI - AITextgen no tokenizer",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "82ec086e8751494bb3ae745cb0650faa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bee8da6c9d8542fbb54f3f118f5a94aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b2ed83568e7f41e0bd31faa7b81873a3",
              "IPY_MODEL_0774c8bc74514760a1d50c2836a3b195"
            ]
          }
        },
        "bee8da6c9d8542fbb54f3f118f5a94aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2ed83568e7f41e0bd31faa7b81873a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e2e79ef72431440b82acff2f335dc990",
            "_dom_classes": [],
            "description": "Fetching checkpoint: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 77,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 77,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0cffd92665624bc693647b659433253f"
          }
        },
        "0774c8bc74514760a1d50c2836a3b195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fe43b6a6fb474ca29aecbe6cf4c55eab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.05M/? [00:13&lt;00:00, 77.6kit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e00c2f8aced644a2bbfd48f77e5f12c3"
          }
        },
        "e2e79ef72431440b82acff2f335dc990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0cffd92665624bc693647b659433253f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe43b6a6fb474ca29aecbe6cf4c55eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e00c2f8aced644a2bbfd48f77e5f12c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27f4905dfc444d1bbcf270ef2e8dc2b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4890d3f972a04583aef8ce1a55402207",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f66eda19fbbd4fc5a0a4f55d53a3f098",
              "IPY_MODEL_1bf2bde8fb4740d980ac68b960693d5a"
            ]
          }
        },
        "4890d3f972a04583aef8ce1a55402207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f66eda19fbbd4fc5a0a4f55d53a3f098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0f58761f669466793e1af36ab93c8b7",
            "_dom_classes": [],
            "description": "Fetching hparams.json: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 90,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 90,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50f9f4bc17b2483eb44cb7b26b83b366"
          }
        },
        "1bf2bde8fb4740d980ac68b960693d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_17546882de1e45b99313fe1eebcc92d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.05M/? [00:02&lt;00:00, 381kit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e19dea2a87b14d959b8caaaf8d181b6f"
          }
        },
        "b0f58761f669466793e1af36ab93c8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50f9f4bc17b2483eb44cb7b26b83b366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17546882de1e45b99313fe1eebcc92d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e19dea2a87b14d959b8caaaf8d181b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "665da03aa44d489999de009b4c9a59d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_61ff866cb16c46a396a5ba154889727f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b9f362453234988a9c42f04eaa38764",
              "IPY_MODEL_e7dd9f0834034f2eb9b1b68ec655db2c"
            ]
          }
        },
        "61ff866cb16c46a396a5ba154889727f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b9f362453234988a9c42f04eaa38764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c688092b2182426fb86c1d37728d6ca9",
            "_dom_classes": [],
            "description": "Fetching model.ckpt.data-00000-of-00001: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 497759232,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 497759232,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5c2c440a33449bd901e05737e577eef"
          }
        },
        "e7dd9f0834034f2eb9b1b68ec655db2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83cd6778e23f4768b418f54bcc3251bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 498M/? [00:02&lt;00:00, 192Mit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae219541bcaa43c19a69e108dc615396"
          }
        },
        "c688092b2182426fb86c1d37728d6ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5c2c440a33449bd901e05737e577eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83cd6778e23f4768b418f54bcc3251bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae219541bcaa43c19a69e108dc615396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12f21bac2ef14d2aa8fe8d2eaaf2590a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f13d4c9089a5427b8eef8af34ccbe129",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fc5a0594256942f8b520176fdda23a0e",
              "IPY_MODEL_706c8ef643654946968e51fd3838a8e5"
            ]
          }
        },
        "f13d4c9089a5427b8eef8af34ccbe129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc5a0594256942f8b520176fdda23a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce6bc2c581a64081ae63230628ea57ff",
            "_dom_classes": [],
            "description": "Fetching model.ckpt.index: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5215,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5215,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c15e984b76e4a17a1f09115555b7d2d"
          }
        },
        "706c8ef643654946968e51fd3838a8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f9e7a042cea2427d85bfd201d43d864d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.05M/? [00:00&lt;00:00, 10.8Mit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_935c2aa859654174bc834f08abb36fa0"
          }
        },
        "ce6bc2c581a64081ae63230628ea57ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c15e984b76e4a17a1f09115555b7d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9e7a042cea2427d85bfd201d43d864d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "935c2aa859654174bc834f08abb36fa0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85aee45895124ab8814f14791255c1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_882699a6f983463dbb185eb3b2eae716",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_75ea6bcc09c54f0186ba41b8f0925b52",
              "IPY_MODEL_0e6848a54a284404883d3ed1ac3158aa"
            ]
          }
        },
        "882699a6f983463dbb185eb3b2eae716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75ea6bcc09c54f0186ba41b8f0925b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a5faa49258a54d4ebabe89d5b43e22cb",
            "_dom_classes": [],
            "description": "Fetching model.ckpt.meta: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 471155,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 471155,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64caf4310c3f41419a1273697921d45d"
          }
        },
        "0e6848a54a284404883d3ed1ac3158aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ac904992ae8c476abce5ae4234d07e67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.05M/? [00:10&lt;00:00, 98.2kit/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf341be37d294f7ebe0a508788514e58"
          }
        },
        "a5faa49258a54d4ebabe89d5b43e22cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64caf4310c3f41419a1273697921d45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac904992ae8c476abce5ae4234d07e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf341be37d294f7ebe0a508788514e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e0c16464e494e5b9a92efcce2348db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b831fef1ada84cefadfd13f6aa670477",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_459609bf646749f2bbc2c15bce6cf5a6",
              "IPY_MODEL_976d7bb63a274ebab9d800b58c5ee419"
            ]
          }
        },
        "b831fef1ada84cefadfd13f6aa670477": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "459609bf646749f2bbc2c15bce6cf5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_840d5696486b4e0f95f4917f3edac975",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9273,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9273,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e162697c0741409fb158821ef5d1ba00"
          }
        },
        "976d7bb63a274ebab9d800b58c5ee419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f99cefa20f584b8f8ec81c937a060ea9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9273/9273 [00:04&lt;00:00, 2134.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d0cf6806b4845b088d50631b7b22286"
          }
        },
        "840d5696486b4e0f95f4917f3edac975": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e162697c0741409fb158821ef5d1ba00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f99cefa20f584b8f8ec81c937a060ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d0cf6806b4845b088d50631b7b22286": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dabad111af8d40fa91422bbf89023133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_edc1b54b8c8f49e89120ee0ae92bc760",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7526a18af58a4e16a930e767af8bec64",
              "IPY_MODEL_737a22905b5b45edae8b32f47d6ace50"
            ]
          }
        },
        "edc1b54b8c8f49e89120ee0ae92bc760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "7526a18af58a4e16a930e767af8bec64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aa75915c3ae84709b1e61f59821eeca2",
            "_dom_classes": [],
            "description": "Loss: 2.061 — Avg: 2.002 — GPU Mem: 7287 MB: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 25000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8242b7315444e3eaa22090d568a9824"
          }
        },
        "737a22905b5b45edae8b32f47d6ace50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_efa3824dc925434f9bb98b61cc676ada",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25000/25000 [2:59:17&lt;00:00,  2.32it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20d3ec80321045f0b10409076dde4894"
          }
        },
        "aa75915c3ae84709b1e61f59821eeca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8242b7315444e3eaa22090d568a9824": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efa3824dc925434f9bb98b61cc676ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20d3ec80321045f0b10409076dde4894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  aitextgen — Train a GPT-2 Text-Generating Model w/ GPU\n",
        "\n",
        "by [Max Woolf](https://minimaxir.com)\n",
        "\n",
        "*Last updated: Jul 5th, 2020*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Colaboratory** using `aitextgen`!\n",
        "\n",
        "For more about `aitextgen`, you can visit [this GitHub repository](https://github.com/minimaxir/aitextgen) or [read the documentation](https://docs.aitextgen.io/).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07df1ab7-6273-484b-c4d8-72d65d0de1f2"
      },
      "source": [
        "# Freeze versions of dependencies for now\n",
        "!pip install transformers==2.9.1\n",
        "!pip install pytorch-lightning==0.7.6\n",
        "\n",
        "!pip install -q aitextgen\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n",
        "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "        level=logging.INFO\n",
        "    )\n",
        "\n",
        "from aitextgen import aitextgen\n",
        "from aitextgen.colab import mount_gdrive, copy_file_from_gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2019.12.20)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 53.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 56.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (3.0.12)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=80c30f750bb4a35f9a5977668dbc66bb07a5091429fd73ce4f846c1c0356b9e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.7.0 transformers-2.9.1\n",
            "Collecting pytorch-lightning==0.7.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/ab/561d1fa6e5af30b2fd7cb4001f93eb08531e1b72976f13eebf7f7cdc021c/pytorch_lightning-0.7.6-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (2.3.0)\n",
            "Requirement already satisfied: pyyaml>=3.13 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (3.13)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (4.41.1)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 38.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (1.18.5)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (0.35.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (3.3.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (0.10.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.17.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.33.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch-lightning==0.7.6) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch-lightning==0.7.6) (0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.6) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.7.6) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.6) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.6) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.6) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.6) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.6) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.6) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.6) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.6) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.7.6) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.6) (0.4.8)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=6399e17a8abeeda499231b2e02d65e36e0b221d02b264a77ff2a1bd59753d232\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "Installing collected packages: future, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed future-0.18.2 pytorch-lightning-0.7.6\n",
            "\u001b[K     |████████████████████████████████| 573kB 12.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 46.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 563kB 45.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 46.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 11.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 51.7MB/s \n",
            "\u001b[?25h  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses a Nvidia P4, an Nvidia T4, or an Nvidia P100 GPU. For finetuning GPT-2 124M, any of these GPUs will be fine, but for text generation, a T4 or a P100 is ideal since they have more VRAM.\n",
        "\n",
        "You can verify which GPU is active by running the cell below. If you want to try for a different GPU, go to **Runtime -> Factory Reset Runtime**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc8744c-f5c8-4aaa-b358-18450cbdef79"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Dec  6 13:04:46 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |     10MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea05e0f6-9c7c-4ca2-f7a0-c557390c8c78"
      },
      "source": [
        "mount_gdrive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jOhakNDKHZ6",
        "outputId": "1aae55ed-c894-4fc8-ce1c-be650970c12a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trRhgNvsH4Wn"
      },
      "source": [
        "## Loading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download and load the GPT-2 model into the GPU. \n",
        "\n",
        "There are several sizes of GPT-2: currently, aitextgen only works with the smallest one:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "\n",
        "The next cell downloads it from Google's servers and saves it in the Colaboratory VM. If the model has already been downloaded, running this cell will reload it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flqSlHjMIeIw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "82ec086e8751494bb3ae745cb0650faa",
            "bee8da6c9d8542fbb54f3f118f5a94aa",
            "b2ed83568e7f41e0bd31faa7b81873a3",
            "0774c8bc74514760a1d50c2836a3b195",
            "e2e79ef72431440b82acff2f335dc990",
            "0cffd92665624bc693647b659433253f",
            "fe43b6a6fb474ca29aecbe6cf4c55eab",
            "e00c2f8aced644a2bbfd48f77e5f12c3",
            "27f4905dfc444d1bbcf270ef2e8dc2b3",
            "4890d3f972a04583aef8ce1a55402207",
            "f66eda19fbbd4fc5a0a4f55d53a3f098",
            "1bf2bde8fb4740d980ac68b960693d5a",
            "b0f58761f669466793e1af36ab93c8b7",
            "50f9f4bc17b2483eb44cb7b26b83b366",
            "17546882de1e45b99313fe1eebcc92d2",
            "e19dea2a87b14d959b8caaaf8d181b6f",
            "665da03aa44d489999de009b4c9a59d4",
            "61ff866cb16c46a396a5ba154889727f",
            "0b9f362453234988a9c42f04eaa38764",
            "e7dd9f0834034f2eb9b1b68ec655db2c",
            "c688092b2182426fb86c1d37728d6ca9",
            "e5c2c440a33449bd901e05737e577eef",
            "83cd6778e23f4768b418f54bcc3251bc",
            "ae219541bcaa43c19a69e108dc615396",
            "12f21bac2ef14d2aa8fe8d2eaaf2590a",
            "f13d4c9089a5427b8eef8af34ccbe129",
            "fc5a0594256942f8b520176fdda23a0e",
            "706c8ef643654946968e51fd3838a8e5",
            "ce6bc2c581a64081ae63230628ea57ff",
            "6c15e984b76e4a17a1f09115555b7d2d",
            "f9e7a042cea2427d85bfd201d43d864d",
            "935c2aa859654174bc834f08abb36fa0",
            "85aee45895124ab8814f14791255c1f0",
            "882699a6f983463dbb185eb3b2eae716",
            "75ea6bcc09c54f0186ba41b8f0925b52",
            "0e6848a54a284404883d3ed1ac3158aa",
            "a5faa49258a54d4ebabe89d5b43e22cb",
            "64caf4310c3f41419a1273697921d45d",
            "ac904992ae8c476abce5ae4234d07e67",
            "bf341be37d294f7ebe0a508788514e58"
          ]
        },
        "outputId": "05b217fd-aabd-44f7-e1ba-6683ef0f2443"
      },
      "source": [
        "ai = aitextgen(tf_gpt2=\"124M\", to_gpu=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/05/2020 00:32:23 — INFO — aitextgen — Downloading the 124M GPT-2 TensorFlow weights/config from Google's servers\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82ec086e8751494bb3ae745cb0650faa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching checkpoint', max=77.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27f4905dfc444d1bbcf270ef2e8dc2b3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching hparams.json', max=90.0, style=ProgressStyle(des…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "665da03aa44d489999de009b4c9a59d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching model.ckpt.data-00000-of-00001', max=497759232.0…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12f21bac2ef14d2aa8fe8d2eaaf2590a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching model.ckpt.index', max=5215.0, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85aee45895124ab8814f14791255c1f0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Fetching model.ckpt.meta', max=471155.0, style=ProgressSt…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "12/05/2020 00:32:26 — INFO — aitextgen — Converting the 124M GPT-2 TensorFlow weights to PyTorch.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Converting TensorFlow checkpoint from /content/aitextgen/124M\n",
            "Loading TF weight model/h0/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h0/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h0/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h0/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h0/ln_1/b with shape [768]\n",
            "Loading TF weight model/h0/ln_1/g with shape [768]\n",
            "Loading TF weight model/h0/ln_2/b with shape [768]\n",
            "Loading TF weight model/h0/ln_2/g with shape [768]\n",
            "Loading TF weight model/h0/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h0/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h0/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h0/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h1/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h1/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h1/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h1/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h1/ln_1/b with shape [768]\n",
            "Loading TF weight model/h1/ln_1/g with shape [768]\n",
            "Loading TF weight model/h1/ln_2/b with shape [768]\n",
            "Loading TF weight model/h1/ln_2/g with shape [768]\n",
            "Loading TF weight model/h1/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h1/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h1/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h1/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h10/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h10/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h10/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h10/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h10/ln_1/b with shape [768]\n",
            "Loading TF weight model/h10/ln_1/g with shape [768]\n",
            "Loading TF weight model/h10/ln_2/b with shape [768]\n",
            "Loading TF weight model/h10/ln_2/g with shape [768]\n",
            "Loading TF weight model/h10/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h10/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h10/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h10/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h11/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h11/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h11/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h11/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h11/ln_1/b with shape [768]\n",
            "Loading TF weight model/h11/ln_1/g with shape [768]\n",
            "Loading TF weight model/h11/ln_2/b with shape [768]\n",
            "Loading TF weight model/h11/ln_2/g with shape [768]\n",
            "Loading TF weight model/h11/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h11/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h11/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h11/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h2/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h2/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h2/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h2/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h2/ln_1/b with shape [768]\n",
            "Loading TF weight model/h2/ln_1/g with shape [768]\n",
            "Loading TF weight model/h2/ln_2/b with shape [768]\n",
            "Loading TF weight model/h2/ln_2/g with shape [768]\n",
            "Loading TF weight model/h2/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h2/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h2/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h2/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h3/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h3/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h3/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h3/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h3/ln_1/b with shape [768]\n",
            "Loading TF weight model/h3/ln_1/g with shape [768]\n",
            "Loading TF weight model/h3/ln_2/b with shape [768]\n",
            "Loading TF weight model/h3/ln_2/g with shape [768]\n",
            "Loading TF weight model/h3/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h3/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h3/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h3/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h4/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h4/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h4/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h4/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h4/ln_1/b with shape [768]\n",
            "Loading TF weight model/h4/ln_1/g with shape [768]\n",
            "Loading TF weight model/h4/ln_2/b with shape [768]\n",
            "Loading TF weight model/h4/ln_2/g with shape [768]\n",
            "Loading TF weight model/h4/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h4/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h4/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h4/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h5/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h5/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h5/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h5/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h5/ln_1/b with shape [768]\n",
            "Loading TF weight model/h5/ln_1/g with shape [768]\n",
            "Loading TF weight model/h5/ln_2/b with shape [768]\n",
            "Loading TF weight model/h5/ln_2/g with shape [768]\n",
            "Loading TF weight model/h5/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h5/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h5/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h5/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h6/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h6/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h6/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h6/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h6/ln_1/b with shape [768]\n",
            "Loading TF weight model/h6/ln_1/g with shape [768]\n",
            "Loading TF weight model/h6/ln_2/b with shape [768]\n",
            "Loading TF weight model/h6/ln_2/g with shape [768]\n",
            "Loading TF weight model/h6/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h6/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h6/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h6/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h7/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h7/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h7/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h7/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h7/ln_1/b with shape [768]\n",
            "Loading TF weight model/h7/ln_1/g with shape [768]\n",
            "Loading TF weight model/h7/ln_2/b with shape [768]\n",
            "Loading TF weight model/h7/ln_2/g with shape [768]\n",
            "Loading TF weight model/h7/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h7/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h7/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h7/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h8/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h8/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h8/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h8/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h8/ln_1/b with shape [768]\n",
            "Loading TF weight model/h8/ln_1/g with shape [768]\n",
            "Loading TF weight model/h8/ln_2/b with shape [768]\n",
            "Loading TF weight model/h8/ln_2/g with shape [768]\n",
            "Loading TF weight model/h8/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h8/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h8/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h8/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h9/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h9/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h9/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h9/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h9/ln_1/b with shape [768]\n",
            "Loading TF weight model/h9/ln_1/g with shape [768]\n",
            "Loading TF weight model/h9/ln_2/b with shape [768]\n",
            "Loading TF weight model/h9/ln_2/g with shape [768]\n",
            "Loading TF weight model/h9/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h9/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h9/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h9/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/ln_f/b with shape [768]\n",
            "Loading TF weight model/ln_f/g with shape [768]\n",
            "Loading TF weight model/wpe with shape [1024, 768]\n",
            "Loading TF weight model/wte with shape [50257, 768]\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h0', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h0', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h0', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h0', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h1', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h1', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h1', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h1', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h10', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h10', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h10', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h10', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h11', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h11', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h11', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h11', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h2', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h2', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h2', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h2', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h3', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h3', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h3', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h3', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h4', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h4', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h4', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h4', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h5', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h5', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h5', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h5', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h6', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h6', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h6', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h6', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h7', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h7', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h7', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h7', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h8', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h8', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h8', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h8', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h9', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h9', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h9', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h9', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['ln_f', 'b']\n",
            "Initialize PyTorch weight ['ln_f', 'g']\n",
            "Initialize PyTorch weight ['wpe']\n",
            "Initialize PyTorch weight ['wte']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Save PyTorch model to aitextgen/pytorch_model.bin\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12/05/2020 00:32:32 — INFO — aitextgen — Loading 124M GPT-2 model from /aitextgen.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Save configuration file to aitextgen/config.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12/05/2020 00:32:37 — INFO — aitextgen — Using the default GPT-2 Tokenizer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/w3wvHhR.png)\n",
        "\n",
        "Upload **any smaller text file** (for example, [a text file of Shakespeare plays](https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt)) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"lyrics.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is large (>10MB), it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM.\n",
        "\n",
        "Additionally, you may want to consider [compressing the dataset to a cache first](https://docs.aitextgen.io/dataset/) on your local computer, then uploading the resulting `dataset_cache.tar.gz` and setting the `file_name`in the previous cell to that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2 in aitextgen. It runs for `num_steps`, and a progress bar will appear to show training progress, current loss (the lower the better the model), and average loss (to give a sense on loss trajectory).\n",
        "\n",
        "The model will be saved every `save_every` steps in `trained_model` by default, and when training completes. If you mounted your Google Drive, the model will _also_ be saved there in a unique folder.\n",
        "\n",
        "The training might time out after 4ish hours; if you did not mount to Google Drive, make sure you end training and save the results so you don't lose them! (if this happens frequently, you may want to consider using [Colab Pro](https://colab.research.google.com/signup))\n",
        "\n",
        "Important parameters for `train()`:\n",
        "\n",
        "- **`line_by_line`**: Set this to `True` if the input text file is a single-column CSV, with one record per row. aitextgen will automatically process it optimally.\n",
        "- **`from_cache`**: If you compressed your dataset locally (as noted in the previous section) and are using that cache file, set this to `True`.\n",
        "- **`num_steps`**: Number of steps to train the model for.\n",
        "- **`generate_every`**: Interval of steps to generate example text from the model; good for qualitatively validating training.\n",
        "- **`save_every`**: Interval of steps to save the model: the model will be saved in the VM to `/trained_model`.\n",
        "- **`save_gdrive`**: Set this to `True` to copy the model to a unique folder in your Google Drive, if you have mounted it in the earlier cells\n",
        "\n",
        "Here are other important parameters for `train()` that are useful but you likely do not need to change.\n",
        "\n",
        "- **`learning_rate`**: Learning rate of the model training.\n",
        "- **`batch_size`**: Batch size of the model training; setting it too high will cause the GPU to go OOM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0e0c16464e494e5b9a92efcce2348db0",
            "b831fef1ada84cefadfd13f6aa670477",
            "459609bf646749f2bbc2c15bce6cf5a6",
            "976d7bb63a274ebab9d800b58c5ee419",
            "840d5696486b4e0f95f4917f3edac975",
            "e162697c0741409fb158821ef5d1ba00",
            "f99cefa20f584b8f8ec81c937a060ea9",
            "2d0cf6806b4845b088d50631b7b22286",
            "dabad111af8d40fa91422bbf89023133",
            "edc1b54b8c8f49e89120ee0ae92bc760",
            "7526a18af58a4e16a930e767af8bec64",
            "737a22905b5b45edae8b32f47d6ace50",
            "aa75915c3ae84709b1e61f59821eeca2",
            "d8242b7315444e3eaa22090d568a9824",
            "efa3824dc925434f9bb98b61cc676ada",
            "20d3ec80321045f0b10409076dde4894"
          ]
        },
        "outputId": "c2705bbf-476b-4990-8d3b-4a0843a1c152"
      },
      "source": [
        "ai.train(file_name,\n",
        "         line_by_line=False,\n",
        "         from_cache=False,\n",
        "         num_steps=25000,\n",
        "         generate_every=1000,\n",
        "         save_every=1000,\n",
        "         save_gdrive=True,\n",
        "         learning_rate=1e-4,\n",
        "         batch_size=1, \n",
        "         )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/05/2020 00:44:41 — WARNING — aitextgen.TokenDataset — You are tokenizing a CSV file, but you did not set line_by_line=True. Please change if unintended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e0c16464e494e5b9a92efcce2348db0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=9273.0), HTML(value='')), layout=Layout(d…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "12/05/2020 00:44:41 — INFO — aitextgen.TokenDataset — Encoding 9,273 rows from lyrics.csv.\n",
            "12/05/2020 00:44:46 — WARNING — aitextgen — pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
            "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "12/05/2020 00:44:46 — INFO — lightning — GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "12/05/2020 00:44:46 — INFO — lightning — TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "12/05/2020 00:44:46 — INFO — lightning — LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dabad111af8d40fa91422bbf89023133",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=25000.0), HTML(value='')), layout=Layout(…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "dreij 't höbste van mich,\n",
            "tot d'r gekker d'r in 't laeve.\n",
            "dreij 't höbste van mich,\n",
            "tot d'r gekker d'r in 't laeve.\n",
            "dreij 't höbste van mich,\n",
            "tot d'r gekker d'r in 't laeve.\n",
            "\n",
            "'t is mich, 't is mich,\n",
            "ein klaore zegge, 't leed is 't laeve.\n",
            "dreij 't büsse van mich,\n",
            "tot d'r gekker d'r in 't laeve.\n",
            "dreij 't höbste van mich,\n",
            "tot d'r gekker d'r in 't laeve.\n",
            "\n",
            "'t is mich, 't is mich,\n",
            "ein klaore zegge, 't leed is 't laeve.\n",
            "dreij 't\n",
            "==========\n",
            "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "ein bös gein leefde auch zoë wis,\n",
            "dao zit mich waerd: 'doe bös gein leefde auch zoë wis,\n",
            "dao zit mich waerd: 'doe bös gein leefde auch zoë wis,\n",
            "dao zit mich waerd: 'doe bös gein leefde auch zoë wis,\n",
            "ich woort mich ein bieës goud\n",
            "dao zit mich waerd: 'doe bös gein leefde auch zoë wis,\n",
            "dao zit mich waerd: 'doe bös gein leefde auch zoë wis',\n",
            "dao zit mich waerd: 'doe bös gein leefde auch zoë wis\n",
            "dao zit mich waerd: 'doe bös gein leefde auch zoë wis'\n",
            "dao zit mich waerd: 'doe bös gein leef\n",
            "==========\n",
            "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "es 't noe ins in 't hendje, dat vingt mich in de loch.\n",
            "es 't noe ins in 't hendje, doa is gans gedans aete,\n",
            "dan weurt 't noe zoe veer same.\n",
            "es 't noe ins in 't hendje, dat vingt mich in de loch.\n",
            "\n",
            "en weurd 't gebeure, dat is weer sjtaon.\n",
            "en weurd 't gebeure, dat is weer sjtaon.\n",
            "daon iech sjpringe, jao, dat is weer soms gezond.\n",
            "\n",
            "'t zoeë is gans gesjaote, ich weit 't noe neet zoeë sjtaote.\n",
            "den drei daag doch jans in mien hart, 't is weer soms sjtaonrefrein\n",
            "es 't noe ins in 't hendje, dan geit 't mer mit ziene kop.\n",
            "\n",
            "==========\n",
            "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ", ich veul mich toch allein maar 't is op mieng mam.\n",
            "\n",
            "de joeks wieke, de eesjte sjieke, dat is 'n sjök.\n",
            "doe höbs in der sjeng: 'heur mich blieve, doe höb ich dich noets gezeen'.\n",
            "de joeks wieke, de eesjte sjieke, dat is 'n sjök.\n",
            "\n",
            "de joeks, d'r joeks-joar, de sjiek en d'r joeks,\n",
            "de sjiek en de sjiek.\n",
            "de joeks en de sjiek, de sjiek en d'r joeks,\n",
            "de joeks en de sjiek, de sjiek, de sjiek.\n",
            "\n",
            "de joeks en de sjiek, de sjiek en de sjiek,\n",
            "de joeks en de sjiek.\n",
            "de joeks en de sjiek\n",
            "==========\n",
            "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "och, och, och, och, och, och, och, och, och,\n",
            "'t geit toch verlore, och, och, och, och, och, och,\n",
            "\n",
            "ich han ooch, ooch, ooch, och, och, och, och, och,\n",
            "\n",
            "och, och, och, och, och, och, och,\n",
            "\n",
            "och, och, och, och, och, och, och, och, och, och,\n",
            "\n",
            "och, och, och, och, och, och, och, och, och,\n",
            "\n",
            "och, och, och, och, och, och, och, och,\n",
            "\n",
            "och, och (4x)\n",
            "\n",
            "och, och, och, och, och, och, och,\n",
            "\n",
            "och, och, och, och, och,\n",
            "==========\n",
            "\u001b[1m6,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m6,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "noe höb geer nao de de kop\n",
            "dao zit mich op de kop!\n",
            "\n",
            "refrein\n",
            "noe höb geer nao de kop\n",
            "dao zit mich op de kop\n",
            "\n",
            "ich höb geer nao de kop\n",
            "dao is 't dan van 't sjoonste\n",
            "dae höb geer nao de kop\n",
            "\n",
            "ich höb geer nao de kop\n",
            "zègk neet op:\n",
            "\n",
            "doe bès geer vreug tot 'n oer of 't bèd\n",
            "dao is 't dan van 't sjoonste\n",
            "dao zit mich op de kop\n",
            "dao zit mich op de kop\n",
            "\n",
            "refrein\n",
            "noe zès geer nao de kop\n",
            "noe höb geer nao de kop\n",
            "dao zit mich op de kop\n",
            "\n",
            "alle luuj vreug tot 'n oer\n",
            "==========\n",
            "\u001b[1m7,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m7,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "op 't terrasie, zoe gek wie de ganse boere,\n",
            "en in de waereldsjtad waas get belaeve,\n",
            "op 't terrasie, zoe gek wie de ganse boere,\n",
            "op 't terrasie, zoe gek wie de ganse boere,\n",
            "op 't terrasie, zoe gek wie de ganse boere.\n",
            "\n",
            "sjtoer vriej en get laeve,\n",
            "höbbe auch gezag,\n",
            "höbbe nog get sjtap,\n",
            "sjtoer vriej en get laeve,\n",
            "höbbe nog get sjtap,\n",
            "sjtoer vriej en get laeve,\n",
            "höbbe nog get sjtap,\n",
            "sjtoer vriej en get laeve,\n",
            "sjtoer vriej en get laeve,\n",
            "sjtoer vriej en get laeve,\n",
            "höbbe nog get sj\n",
            "==========\n",
            "\u001b[1m8,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m8,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ", dee kump zo sjtoots, en höb iech hiel väöl plezeer.\n",
            "lekker oet de taffel, euveral, driej daog weer.\n",
            "meh daan weurt 't gans verleef, en daan zien iech weer.\n",
            "iech weer, jao, iech weer, jao, iech weer, jao, iech weer.\n",
            "\n",
            "refrein\n",
            "iech höb 't gezellig, iech höb gezellig, iech höb gezellig neet mie.\n",
            "iech höb 't gezellig, iech höb gezellig neet mie.\n",
            "iech höb 't gezellig, iech höb gezellig neet mie.\n",
            "\n",
            "wie 'ch in de taffel höb, geer hoale wie 'ne kleine zaog.\n",
            "iech höb d'n ooievaank, dat höb\n",
            "==========\n",
            "\u001b[1m9,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m9,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            " zal daag drei daag goon,\n",
            "daan zeen de boerebroel die gedoon.\n",
            "\n",
            "d'n bèrreg is zoe leuk, dat is toch eine vrauwe,\n",
            "mien hert-ste kump toch hart verkleid, en de prins is häöm de lèste kieke.\n",
            "daan zeen v'r gaar neet vergete, en de vrouw is in de boerebroel.\n",
            "\n",
            "eine sjlaag in de optocht, dat is toch eine kier\n",
            "ich häöm nog 'ns aeve, want dat is toch 'n sjoen houdje.\n",
            "nè, dat is toch 'n sjoen houdje, dat is toch 'n sjoen houdje.\n",
            "\n",
            "'t is gein ech get te beginne, dat is toch 'n sjoen doedgeweune.\n",
            "ich bèn neet zo sjoen, dat is toch toch e\n",
            "==========\n",
            "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "noe veuls te veur, en veer goon nog neet komme,\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "veer goon nog neet komme\n",
            "==========\n",
            "\u001b[1m11,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m11,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "en den echte kwiebus, die zunt werm 'ne sjwiebus\n",
            "woar 't miech karnaval vuur óp sjpringe is\n",
            "'t is huu al lang gelieërdj\n",
            "\n",
            "de vieër deet jing sjtuk\n",
            "de sjtiemmoeng die d'r kriebel al jaore bij\n",
            "d'r mieë hat 't nuuske óp zieng zieër\n",
            "d'r mieë hat 't nuuske óp zieng zieër\n",
            "\n",
            "de mieë hult d'r kriebel werm paraat\n",
            "'t hüet ziech d'r kriebel van de keuning i sjtraat\n",
            "'t is d'r kriebel al gesjtopd\n",
            "de mieë hult d'r kriebel van de keuning i sjtraat\n",
            "\n",
            "'t hüet ziech d'r kriebel van de ke\n",
            "==========\n",
            "\u001b[1m12,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m12,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "en ik zoog dich, en ik hald van dich.\n",
            "ik zeen dich allein 'n wonder,\n",
            "weej zien neet mier nao hoés, tot aswoensdigs gedoan.\n",
            "\n",
            "ik hald van dich.\n",
            "ik hald van dich.\n",
            "ik zeen dich allein 'n wonder,\n",
            "weej zien neet mier nao hoés, tot aswoensdigs gedoan.\n",
            "\n",
            "dich bis mien beste vreej, det is mien beste vreej.\n",
            "ich hald van dich, det is mien beste vreej.\n",
            "ik hald van dich, det is mien beste vreej.\n",
            "ik hald van dich, det is mien beste vreejich zeen dich door de sjtraote, en dan in mien hart\n",
            "ich zegk dich taege, 't ganse zaol oet mien bein\n",
            "en bin ein gek aan de gangk, en zitte ein ander lank\n",
            "==========\n",
            "\u001b[1m13,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m13,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "\n",
            "'t ganse dörp klopt van 't laeve.\n",
            "want kiek 't ôs nao miene kop.\n",
            "en dink 't, deze, deze,\n",
            "van ôs nao 't hoes.\n",
            "de ganse dörp is ôs zoë vlot.\n",
            "de kastelein, de kastelein,\n",
            "mót 't oet.\n",
            "\n",
            "refrein\n",
            "de vastelaovend gaon weer op stap.\n",
            "weer gaon ós dekker op stap.\n",
            "det is ós wat viere waat 't is.\n",
            "de vastelaovend gaon weer op stap.\n",
            "weer gaon ós dekker op stap.\n",
            "\n",
            "weej zien d'r oétverkiering vanein.\n",
            "d'r is mich vleugels te doon.\n",
            "maar ut zit in venlo nog in 't graas.\n",
            "de kastelein dae kump d\n",
            "==========\n",
            "\u001b[1m14,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m14,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            " aaf en toe aan de tap\n",
            "wie veer dan waere allemaol\n",
            "zal ze dan neet mier goan\n",
            "en sjtingt noe gans vanzelf aan ein traon\n",
            "en sjtingt noe gans vanzelf aan ein traon\n",
            "in traon en sjtingt noe gans vanzelf aan ein traon\n",
            "in traon en sjtingt noe gans vanzelf aan ein traon\n",
            "tante fien, tante fien, tante sjtaof\n",
            "\n",
            "'t is weer zo wiejer\n",
            "veer zeen mèt en lekker mèt\n",
            "en sjtingt noe gans vanzelf aan ein traon\n",
            "en sjtingt noe gans vanzelf aan ein traon\n",
            "dao sjtingt noe gans vanzelf aan ein traon\n",
            "en sjtingt noe gans vanzelf aan ein traon\n",
            "dan zeen wae wiejer\n",
            "==========\n",
            "\u001b[1m15,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m15,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "-eine sjaele kleine poet,\n",
            "wat is dat toch oet de handj?\n",
            "dèns-te nog hiej, dèns-te nog hiej,\n",
            "wae höbbe al hiej gezaete,\n",
            "ich kom ouch hiej van noe.\n",
            "\n",
            "refrein\n",
            "wat höbbe veer oos toch gedaon?\n",
            "wat höbbe veer oos toch gedaon?\n",
            "wat höbbe veer oos toch gedaon?\n",
            "wat höbbe veer oos toch gedaon?\n",
            "wat höbbe veer oos toch gedaon?\n",
            "wat höbbe veer oos toch gedaon?\n",
            "wat höbbe veer oos toch gedaon?\n",
            "wat höbbe veer oos toch gedaon?\n",
            "wat höbbe veer oos toch gedaon?\n",
            "wat höbbe veer oos toch gedaon\n",
            "==========\n",
            "\u001b[1m16,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m16,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "\n",
            "refrein\n",
            "\n",
            "'t is waor 't vastelaovend, 't is al laat.\n",
            "'t is vastelaovend, 't is al gedaon.\n",
            "'t is waor 't vastelaovend, 't is al gedaon.\n",
            "\n",
            "couplet\n",
            "\n",
            "couplet\n",
            "\n",
            "de vlaggelekke, die zin d'n hiele wereldsjtad.\n",
            "de sjpek mit mieng blome, de sjtumming in de boet.\n",
            "d'r opa kump d'r beij 't vuur, d'r opa kump d'r ierste kier.\n",
            "de vlaggelekke, die zin d'n hiele wereldsjtad.\n",
            "de vlaggelekke, die zin d'n hiele wereldsjtad.\n",
            "\n",
            "couplet\n",
            "\n",
            "de kastelein is in de vreugde luij.\n",
            "d'r opa k\n",
            "==========\n",
            "\u001b[1m17,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m17,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            " wètste dat daan toch zoepe?\n",
            "maak 't dich neet zoewiet, en daan zegk ich: wat hei dat toch gebeurd.\n",
            "\n",
            "iech hoop tot 't in 't geet, tot 't's aovends laat zien veer neet.\n",
            "want zie heet 't geziech, en iech pak miech d'ch get vaan.\n",
            "want zie heet 't geziech, en iech pak miech d'ch get vaan.\n",
            "\n",
            "iech hoop tot 't in 't geet, tot 't's aovends laat zien veer neet.\n",
            "want zie heet 't geziech, en iech pak miech d'ch get vaan.\n",
            "\n",
            "iech hoop tot 't in 't geet, tot 't's aovends laat zien veer neet.\n",
            "want zie heet 't geziech, en iech pak miech d'ch get vaan\n",
            "==========\n",
            "\u001b[1m18,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m18,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "maak dien ganse laeve langk op dien gemaak\n",
            "krieg det duit mich good\n",
            "det deej eur waal ens huure\n",
            "en den krieg hae soms zoeë lekker mit\n",
            "dus laot eur lekker gaon\n",
            "en haet 't zich zelf gedaon\n",
            "\n",
            "'t geit mich neet lang, dus ik veul mich good\n",
            "det geit mich op en top\n",
            "maar ik ligk op dien snuut\n",
            "en d'r zit mit mien schoon\n",
            "maar ik loup langs de lien\n",
            "en det dink beej mich\n",
            "det is mich gans gewoen\n",
            "dus laot eur lekker gaon\n",
            "en den krieg hae soms zoeë lekker mit\n",
            "dus laot eur lekker gaonrefrein\n",
            "de zon sjleit op klank, de létste daag vaan d'n tied.\n",
            "de z\n",
            "==========\n",
            "\u001b[1m19,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m19,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            " weit 't zeker, zo'n korte brook gevoonde.\n",
            "\n",
            "de ganse wereld sjteit nog 't koffer op de kop,\n",
            "de vuur höbbe get gehad in de ganse nach.\n",
            "de ganse wereld sjteit nog 't koffer op de kop,\n",
            "de vuur höbbe get gehad in de ganse nach.\n",
            "\n",
            "de ganse wereld viert me ech 't koffer good,\n",
            "d'n tied is noe gans besjtange.\n",
            "de ganse wereld sjteit nog 't koffer op de kop,\n",
            "de vuur höbbe get gehad in de ganse nachrefrein\n",
            "de ganse wereld luije, de ganse wereld luije,\n",
            "'t is weer vasteloavend.\n",
            "'t is weer vasteloavend.\n",
            "'t is weer vasteloavend.\n",
            "\n",
            "sjoen is 't in 't r\n",
            "==========\n",
            "\u001b[1m20,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m20,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "\n",
            "ze kieke hie nao 't graasboerinne\n",
            "de sjterre en de karreboer\n",
            "dao hingk mit mich de sjterre biej\n",
            "mer det is ein sjoean gezich\n",
            "wiej det v'r vanaovend wurt\n",
            "of 't noe toch noe beginne\n",
            "mer det is neet erg\n",
            "det hèltj veer toch zo vrie\n",
            "\n",
            "refrein\n",
            "dus zetj os noe mer op\n",
            "'t leave het waal 'n pruuk\n",
            "want auch doon dao d'r toch aan\n",
            "en wat kiek dae lach, deeg mer aan\n",
            "\n",
            "doe mos dich nog ens get kieke woor\n",
            "dus zetj os mer op\n",
            "'n pruuk of neet op\n",
            "ich dink det ich hej nog hej\n",
            "want ich hej dao hiej op\n",
            "want ich zit noe mer in\n",
            "==========\n",
            "\u001b[1m21,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m21,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "j kômme ouch nog get,\n",
            "die lache, danse, sjpringe.\n",
            "\n",
            "de vastenaovendj, den is 't sjoon,\n",
            "die höbbe völ meziek.\n",
            "die sjpeule mit 'ne lach,\n",
            "de zöstere sjteul aan ein vlank.\n",
            "en ein, twie, drie, drei, drej,\n",
            "de vastenaovendj, den is 't sjoon.\n",
            "\n",
            "de klok is den oet, den make völ plezeer,\n",
            "den sjtaon weer te sjtömme in de boek.\n",
            "want door 't laeve is de vastenaovend,\n",
            "den sjpringe veur klok en gezank.\n",
            "en ein, twie, drie, drei, drei,\n",
            "de vastenaovendj, den is 't sjoon.\n",
            "\n",
            "refrein\n",
            "de vastenaovendj\n",
            "==========\n",
            "\u001b[1m22,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m22,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            " in de kelder of tót de sjleere.\n",
            "en de deur die zien veur sjleipe.\n",
            "en de meziek zien kelder sjteit neet mieë rónd,\n",
            "toch blief ich in de waereldsjtad d'r sjmaak\n",
            "ich weit 't zeker, maar ich zeuk mich d'r aan\n",
            "en es ich in de kelder weer kómme, dan veul ich mich rónd.\n",
            "\n",
            "refrein\n",
            "kóm, sjmiet dich èns in, dae kolder in de lóch,\n",
            "en de kolder is óm dichterbiej.\n",
            "kóm, sjmiet dich èns in, de kolder in de lóch,\n",
            "en ich zeuk mich d'r aan, en sjmaak mich rónd.\n",
            "\n",
            "ich höb 't zeker d'r aan de kloes,\n",
            "en zit\n",
            "==========\n",
            "\u001b[1m23,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m23,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            "-o-weg, al-hèl-èf-jes.\n",
            "\n",
            "is d'r wieëtsjte klòmmel-oer,\n",
            "da zaan ich: 't is nog hieël sjoeën, vuer dich, vuer dich, vuer mich.\n",
            "ich wieëtsjte wie ich vreuger kòm, en zègk aan dat klòmmel-sjtòm.\n",
            "ich wieëtsjte wie ich hiej oos goud gelouf, en ich weëd zoa gaer gelieërd.\n",
            "\n",
            "al woa ich hie nog nieks meëjlik zieë, doa weëd ich aan'm nieks mieëd.\n",
            "dat woeëte sjtil en wieëte sjteël, dat is mich alles waer.\n",
            "joa, ich zèng èns hieël vöal luu\n",
            "==========\n",
            "\u001b[1m24,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m24,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            ",\n",
            "dât kôs ni wao weej.\n",
            "en dât ik ok ni aan verdeen,\n",
            "det deurt ôs gen idee.\n",
            "nae, ik heb ni zoë sleum verteld,\n",
            "ik zal dât ni beej.\n",
            "\n",
            "as weej hiël euver tiën maon zien,\n",
            "bin ik eur toch gen kwaol verstaon,\n",
            "waorum heej nao ônder.\n",
            "dât is ôzze zaege,\n",
            "dât is nôw ni gedaon.\n",
            "maar ôs mam die zien al vuül kwaod,\n",
            "dât is allang neet mâr zeuke,\n",
            "en nao en versiere kwaod.\n",
            "ik weit zeker wie zeej zien,\n",
            "dât hald ik oët gewuün.\n",
            "\n",
            "ik heb 't toch nog noëts gehuurd,\n",
            "w\n",
            "==========\n",
            "\u001b[1m25,000 steps reached: saving model to /trained_model\u001b[0m\n",
            "\u001b[1m25,000 steps reached: generating sample texts.\u001b[0m\n",
            "==========\n",
            " heej en dao ut zinge op de jrök.\n",
            "\n",
            "de vastelaovendtj veere zeen, dae hieël gezondj,\n",
            "de sjtumming heat auch oet zien wang, dae haaje zich gein gezich:\n",
            "de prins dae hieët ut wirke, dae kloptj hieël gezondj,\n",
            "mer zek ut nog get wieër, de zetjes los mer in zichrefrein\n",
            "wat is toch hiej, nae det kumptj d'r noe d'r biej,\n",
            "met di-j daag auch de handj oppe waage.\n",
            "allein mer dao, di-j kunne neet nao, d'r biej met di-j daag.\n",
            "jao, wae gaon noe same nao de rog, unne daag vanaovundj lao.\n",
            "zoee gaon wae same nao de rog, un\n",
            "==========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "12/05/2020 03:43:56 — INFO — aitextgen — Saving trained model pytorch_model.bin to /trained_model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "\n",
        "## Load a Trained Model\n",
        "\n",
        "Running the next cell will copy the `pytorch_model.bin` and the `config.json`file from the specified folder in Google Drive into the Colaboratory VM. (If no `from_folder` is specified, it assumes the two files are located at the root level of your Google Drive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "from_folder = 'ATG_20201205_003216'\n",
        "\n",
        "for file in [\"pytorch_model.bin\", \"config.json\"]:\n",
        "  if from_folder:\n",
        "    copy_file_from_gdrive(file, from_folder)\n",
        "  else:\n",
        "    copy_file_from_gdrive(file)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model + metadata necessary to generate text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4eb254-f836-4618-a186-c79d3471a9f5"
      },
      "source": [
        "ai = aitextgen(model=\"pytorch_model.bin\", config=\"config.json\", to_gpu=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12/06/2020 13:07:26 — INFO — aitextgen — Loading GPT-2 model from provided pytorch_model.bin.\n",
            "12/06/2020 13:07:31 — INFO — aitextgen — Using the default GPT-2 Tokenizer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate()` without any parameters generates a single text from the loaded model to the console."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afdd0b66-87a4-409d-fa5b-c3a4e03d2fd9"
      },
      "source": [
        "ai.generate()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[0min gedachte doon ich dat neet.\r\n",
            "ich kiek dao ein dink altied ein mötske in mien bed.\r\n",
            "dao zal ich neet wao ich zeen, dao maak ich mich döks van.\r\n",
            "\r\n",
            "refrein\r\n",
            "nemes dans mich en doe en ich dans mich en doe en ich zulle mich\r\n",
            "same gaon, same sjtaon, same zjwaege doon.\r\n",
            "'t maak niks oet wie ich sjlech, mer 't maak niks oet wie ich sjlech, mer 't maak niks oet wie ich sjlech,\r\n",
            "mer 't maak niks oet wie ich sjlech, mer 't maak niks oet wie ich sjlech.\r\n",
            "\r\n",
            "ich zeen dich, dao wurt ein paradies, dao ken ich weer waal biej dien kans\r\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = ai.generate_one()`\n",
        "\n",
        "You can also pass in a `prompt` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `n`. You can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 50 for `batch_size` to avoid going OOM).\n",
        "\n",
        "Other optional-but-helpful parameters for `ai.generate()` and friends:\n",
        "\n",
        "*  **`max_length`**: Number of tokens to generate (default 256, you can generate up to 1024 tokens with GPT-2, but it will be _much_ slower)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef4362ea-5d50-46ea-b3d6-640f882a3b2b"
      },
      "source": [
        "ai.generate(n=5,\n",
        "            batch_size=5,\n",
        "            prompt=\"\",\n",
        "            max_length=256,\n",
        "            temperature=1.0,\n",
        "            top_p=0.9)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m\u001b[0me kwiet\r\n",
            "noe laot dich mer hiej zeen!!\r\n",
            "want dae de karnaval is gedoan!!\r\n",
            "vastelaovendj, dae hiltj van oos laeve inne loch\r\n",
            "gaon alle daag flink oppe maot van laotjes d'r nao hoes toe gaon, daonao 't kefeekes.\r\n",
            "dae wurt weer ens wakker, maar daoveur steit nag d'r töpke.\r\n",
            "dae vluugtj ós de sjtömming in, van de allerletste sjtömming.\r\n",
            "en nag d'r nag ein pilske veur, den zuutj eder jaor weer gaer.\r\n",
            "en det duit eder jaor weer, die d'r dao in zuzaote.\r\n",
            "maar och, waat duit die mam met ós gaer.\r\n",
            "\r\n",
            "refrein\r\n",
            "die dao is gaer op vastela\n",
            "==========\n",
            "\u001b[1m\u001b[0mer ies unne högk of twiefelzak\r\n",
            "\r\n",
            "de ganse daag gaon d'r weer op stap\r\n",
            "ze dans de kroeg en zinge door de maot\r\n",
            "jao det zit vol, maar dan in det leuke vaat\r\n",
            "\r\n",
            "refrein\r\n",
            "de ganse daag weer veurluipig neet allein\r\n",
            "de ganse daag is veur mich allein\r\n",
            "dus den huurse auch al mien druime alweer beejein\r\n",
            "de ganse daag weer veurluipig neet allein\r\n",
            "dus den huurse auch al mien druime, veur mich allein\r\n",
            "\r\n",
            "op ein jaor of twelf oere vraog ich dich: dao kinse niks aan doon\r\n",
            "det ich dich mer bekans, die ich dich noeits mier sjtaon\r\n",
            "\r\n",
            "det ich dich dink maak auch vief, det geveul van michrefrein\r\n",
            "de ganse\n",
            "==========\n",
            "\u001b[1m\u001b[0m mien vader nog get aan\r\n",
            "dae vastelaovend, det wuurd getaoge\r\n",
            "dan is 't veur mich allein.\r\n",
            "doe zaes dan: 'die zeen weer zoea gaer\r\n",
            "nag efkes twee bóntje klank'\r\n",
            "'n fles veur eder jaor al die jaore\r\n",
            "die kènne d'r neet taege\r\n",
            "nemes sjteit al waeke in de gangk\r\n",
            "en de sjoonste vader sjtraolt oet de loch\r\n",
            "die gank de kamer ein glaeske beer\r\n",
            "\r\n",
            "de sjoonste vader sjtraolt oet de loch\r\n",
            "dao keump d'r sjlaope op\r\n",
            "en de res is oos kruuts en sjtök\r\n",
            "veur die daag waal effe sjtoan\r\n",
            "de prins dae is dan oos plek.\r\n",
            "van sjtolz dao geit 't baovenal\n",
            "==========\n",
            "\u001b[1m\u001b[0mt veur de leefde\r\n",
            "want noe geit 't wie geweun\r\n",
            "en noe geit 't wie geweun\r\n",
            "\r\n",
            "zoea geit dat aan en boete d'n hamer\r\n",
            "en boete d'n hamer en boete d'n hamer\r\n",
            "en boete d'n hamer en boete d'n hamer\r\n",
            "\r\n",
            "want noe geit 't wie geweun\r\n",
            "en noe geit 't wie geweun\r\n",
            "en noe geit 't wie geweun\r\n",
            "en noe geit 't wie geweun\r\n",
            "en noe geit 't wie geweun\r\n",
            "\r\n",
            "drie daag lank goan weej lekker oet\r\n",
            "de boeten 't mooi zin gebroet\r\n",
            "van alles dat kin zinge\r\n",
            "en dit is 't leave d'rvan\r\n",
            "de pien die is kloar\r\n",
            "en de pien die is kloar\r\n",
            "en de pien\n",
            "==========\n",
            "\u001b[1m\u001b[0mt.\r\n",
            "'t woar tevreejje um de joekskepel te klein\r\n",
            "mer iech ging vrije naor 't aovends sjteig\r\n",
            "en wie iech langs 't mecc, 't woar zoe gelökkig.\r\n",
            "\r\n",
            "toen iech eederein tege moos woare zaog iech\r\n",
            "es iech miech get op 'ne kop ging stoond\r\n",
            "en opins koam d'r vandoor de meute op\r\n",
            "iech sjpiejde d'r eindeloze op en zag:\r\n",
            "\r\n",
            "de ganse zaak, dee maakde ziech neet oet\r\n",
            "wie iech dee knäök in 't gelid vaan binne keek\r\n",
            "de kloone achter de ziech\r\n",
            "meh 't haange woar achter de keers\r\n",
            "dee sjoenkelt miech noe in 't glaas beer\r\n",
            "daan dach iech: wie dee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of texts to a file and sort out the samples locally on your computer. The next cell will generate `num_files` files, each with `n` texts and whatever other parameters you would pass to `generate()`. The files can then be downloaded from the Files sidebar!\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "num_files = 5\n",
        "\n",
        "for _ in range(num_files):\n",
        "  ai.generate_to_file(n=1000,\n",
        "                     batch_size=50,\n",
        "                     prompt=\"ROMEO:\",\n",
        "                     max_length=256,\n",
        "                     temperature=1.0,\n",
        "                     top_p=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2020 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}